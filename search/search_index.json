{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hyperledger Blockchain Performance This site represents a collaborative collection and presentation of Hyperledger Blockchain performance reports, using the metrics defined within the Hyperledger Performance and Scale Working Group's white paper titled Hyperledger Blockchain Performance Metrics and generated using Hyperledger Caliper. Contained reports are intended to provide key processing and performance characteristics to architects, systems programmers, analysts and programmers. For best use of the performance reports, the user should be familiar with the concepts and operation of the technology under test. Within this site you will find performance reports for Hyperledger Blockchain technologies covering: API tests: Deep dive investigation into the performance implications of API useage for a specific Hyperledger technology Sample tests: A test that is focussed on a sample provided for a specific Hyperledger technology Scenario tests: A test that involves the completion of a task, and is applicable to all Hyperledger technologies All test resources used to generate the contained reports are available within the Caliper Benchmarks repository Notes The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform under test. The data contained in listed reports were measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources section at the end of all available reports. The performance data cannot be compared across versions of a blockchain technology, as testing hardware and environments may be significantly different. The testing contents and processing methodologies may have also changed between performance reports, and so these cannot be compared.","title":"Overview"},{"location":"#hyperledger-blockchain-performance","text":"This site represents a collaborative collection and presentation of Hyperledger Blockchain performance reports, using the metrics defined within the Hyperledger Performance and Scale Working Group's white paper titled Hyperledger Blockchain Performance Metrics and generated using Hyperledger Caliper. Contained reports are intended to provide key processing and performance characteristics to architects, systems programmers, analysts and programmers. For best use of the performance reports, the user should be familiar with the concepts and operation of the technology under test. Within this site you will find performance reports for Hyperledger Blockchain technologies covering: API tests: Deep dive investigation into the performance implications of API useage for a specific Hyperledger technology Sample tests: A test that is focussed on a sample provided for a specific Hyperledger technology Scenario tests: A test that involves the completion of a task, and is applicable to all Hyperledger technologies All test resources used to generate the contained reports are available within the Caliper Benchmarks repository","title":"Hyperledger Blockchain Performance"},{"location":"#notes","text":"The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform under test. The data contained in listed reports were measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources section at the end of all available reports. The performance data cannot be compared across versions of a blockchain technology, as testing hardware and environments may be significantly different. The testing contents and processing methodologies may have also changed between performance reports, and so these cannot be compared.","title":"Notes"},{"location":"content/license/","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"{}\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright {yyyy} {name of copyright owner} Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"content/common/inprogress/","text":"Page In Progress We are working on content for this location ... please check back later, or help us build it!","title":"Tools"},{"location":"content/common/inprogress/#page-in-progress","text":"We are working on content for this location ... please check back later, or help us build it!","title":"Page In Progress"},{"location":"content/community/chat/","text":"Rocket Chat You can find us on the following Rocket Chat channels: Caliper Performance and Scale Workgroup","title":"RocketChat"},{"location":"content/community/chat/#rocket-chat","text":"You can find us on the following Rocket Chat channels: Caliper Performance and Scale Workgroup","title":"Rocket Chat"},{"location":"content/community/contribute/","text":"Contribute Happy to see you here and reading the contribution section! We are looking to expand the number of repeatable test cases and subsequent analysis contained in this site - if you have an item to contribute, or are looking to contribute, then please reach out to us.","title":"Contribute"},{"location":"content/community/contribute/#contribute","text":"Happy to see you here and reading the contribution section! We are looking to expand the number of repeatable test cases and subsequent analysis contained in this site - if you have an item to contribute, or are looking to contribute, then please reach out to us.","title":"Contribute"},{"location":"content/fabric/approach/","text":"Performance observations are obtained from testing Hyperledger Fabric smart contracts, driven by Fabric-SDK-Node clients through a series of benchmarks; the test topology is given in Figure 1 below Figure 1: Test Topology During benchmarking, all transactions are driven via a Hyperledger Fabric client gateway. Throughput and latencies for each benchmark are measured, as are resource statistics during the benchmark process. The Smart Contract All benchmarks are facilitated by the fixed-asset smart contract that is deployed to the Hyperledger Fabric network. The smart contract facilitates the driving of core API methods that are commonly used by a smart contract developer. Smart Contract Method Description emptyContract Immediately returns an empty response and represents the minimum possible overhead incurred through evaluation or submission of a smart contract method via a gateway. createAsset Performs a single putState() operation, inserting an asset of defined byte size into the World State database. createAssetsFromBatch Performs multiple putState() operations over an array of assets, inserting each into the World State database. getAsset Performs a single getState() operation, extracting and returning a single asset from the World State database using a passed UUID. getAssetsFromBatch Performs multiples getState() operations over an array of asset UUIDs, extracting and returning all asset from the World State database. paginatedRangeQuery Performs a getStateByRangeWithPagination() operation, based on passed start/end keys, a desired page size and passed bookmark. The records obtained from the query are processed and returned in a JSON response that also includes a new bookmark. paginatedRichQuery Performs a getQueryResultWithPagination() operation, based on a passed Mango query string, a desired page size and bookmark. The records obtained from the query are processed and returned in a JSON response that also includes a new bookmark. Only valid for deployments including a CouchDB World State database. Smart contract methods may be evaluated or submitted via a Fabric Network gateway. An overview of possible transaction pathways from a client application interacting with Hyperedger Fabric is presented in Figure 1. Evaluation of a smart contract method will not include interaction with the ordering service, and consequently will not result in appending to the leger; submission of a smart contract will result on the method being run on Hyperledger Fabric Peers as required by the endorsement policy and appended to the ledger by the ordering service. Figure 1: Possible Transaction Pathways Smart Contract Benchmarks The complete output of the benchmark runs, and the resources used to perform them, are in the resources section of the Appendix. All benchmarks are driven at maximum possible TPS for a duration of 5 minutes by multiple test clients. This is followed by a driving the benchmarks at a set TPS for a duration of 5 minutes by multiple test clients to enable resource utilization comparisons. The benchmarks comprise of: Benchmark Config Files Description Empty Contract empty-contract-1of.yaml, empty-contract-2of.yaml Evaluates and submits emptyContract gateway transactions for the fixed-asset smart contract. This transaction performs no action. Repeated for different Endorsement Policies. Create Asset create-asset.yaml Submits createAsset gateway transactions for the fixed-asset smart contract. Each transaction inserts a single asset into the world state database. Successive rounds increase the asset byte size inserted into the world state database. Create Asset Batch create-asset-batch.yaml Submits createAssetsFromBatch gateway transactions for the fixed-asset smart contract. Each transaction inserts a sequence of fixed size assets into the world state database. Successive rounds increase the batch size of assets inserted into the world state database. Get Asset get-asset.yaml Evaluates getAsset gateway transactions for the fixed-asset smart contract. Each transaction retrieves a single asset from the world state database. Successive rounds increase the asset byte size retrieved from the world state database. Get Asset Batch get-asset-batch.yaml Evaluates getAssetsFromBatch gateway transactions for the fixed-asset smart contract. Each transaction retrieves a series of assets from the world state database. Successive rounds increase the batch size of assets retrieved from the world state database. Paginated Range Query mixed-range-query-pagination.yaml Evaluates paginatedRangeQuery gateway transactions for the fixed-asset smart contract. Each transaction retrieves a set of assets from the world state database. Successive rounds increase the page size of assets retrieved from the world state database. Paginated Rich Query mixed-rich-query-pagination.yaml Evaluates paginatedRichQuery gateway transactions for the fixed-asset smart contract. Each transaction retrieves a set of assets from the world state database. Successive rounds increase the page size of assets retrieved from the world state database. Notes The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform. The data contained in the reports was measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources at the end of this report. The performance data cannot be compared across versions of Hyperledger Fabric, as testing hardware and environments may have changed significantly. The testing contents and processing methodologies may have also changed between performance reports, and so cannot be compared.","title":"Approach"},{"location":"content/fabric/approach/#the-smart-contract","text":"All benchmarks are facilitated by the fixed-asset smart contract that is deployed to the Hyperledger Fabric network. The smart contract facilitates the driving of core API methods that are commonly used by a smart contract developer. Smart Contract Method Description emptyContract Immediately returns an empty response and represents the minimum possible overhead incurred through evaluation or submission of a smart contract method via a gateway. createAsset Performs a single putState() operation, inserting an asset of defined byte size into the World State database. createAssetsFromBatch Performs multiple putState() operations over an array of assets, inserting each into the World State database. getAsset Performs a single getState() operation, extracting and returning a single asset from the World State database using a passed UUID. getAssetsFromBatch Performs multiples getState() operations over an array of asset UUIDs, extracting and returning all asset from the World State database. paginatedRangeQuery Performs a getStateByRangeWithPagination() operation, based on passed start/end keys, a desired page size and passed bookmark. The records obtained from the query are processed and returned in a JSON response that also includes a new bookmark. paginatedRichQuery Performs a getQueryResultWithPagination() operation, based on a passed Mango query string, a desired page size and bookmark. The records obtained from the query are processed and returned in a JSON response that also includes a new bookmark. Only valid for deployments including a CouchDB World State database. Smart contract methods may be evaluated or submitted via a Fabric Network gateway. An overview of possible transaction pathways from a client application interacting with Hyperedger Fabric is presented in Figure 1. Evaluation of a smart contract method will not include interaction with the ordering service, and consequently will not result in appending to the leger; submission of a smart contract will result on the method being run on Hyperledger Fabric Peers as required by the endorsement policy and appended to the ledger by the ordering service. Figure 1: Possible Transaction Pathways","title":"The Smart Contract"},{"location":"content/fabric/approach/#smart-contract-benchmarks","text":"The complete output of the benchmark runs, and the resources used to perform them, are in the resources section of the Appendix. All benchmarks are driven at maximum possible TPS for a duration of 5 minutes by multiple test clients. This is followed by a driving the benchmarks at a set TPS for a duration of 5 minutes by multiple test clients to enable resource utilization comparisons. The benchmarks comprise of: Benchmark Config Files Description Empty Contract empty-contract-1of.yaml, empty-contract-2of.yaml Evaluates and submits emptyContract gateway transactions for the fixed-asset smart contract. This transaction performs no action. Repeated for different Endorsement Policies. Create Asset create-asset.yaml Submits createAsset gateway transactions for the fixed-asset smart contract. Each transaction inserts a single asset into the world state database. Successive rounds increase the asset byte size inserted into the world state database. Create Asset Batch create-asset-batch.yaml Submits createAssetsFromBatch gateway transactions for the fixed-asset smart contract. Each transaction inserts a sequence of fixed size assets into the world state database. Successive rounds increase the batch size of assets inserted into the world state database. Get Asset get-asset.yaml Evaluates getAsset gateway transactions for the fixed-asset smart contract. Each transaction retrieves a single asset from the world state database. Successive rounds increase the asset byte size retrieved from the world state database. Get Asset Batch get-asset-batch.yaml Evaluates getAssetsFromBatch gateway transactions for the fixed-asset smart contract. Each transaction retrieves a series of assets from the world state database. Successive rounds increase the batch size of assets retrieved from the world state database. Paginated Range Query mixed-range-query-pagination.yaml Evaluates paginatedRangeQuery gateway transactions for the fixed-asset smart contract. Each transaction retrieves a set of assets from the world state database. Successive rounds increase the page size of assets retrieved from the world state database. Paginated Rich Query mixed-rich-query-pagination.yaml Evaluates paginatedRichQuery gateway transactions for the fixed-asset smart contract. Each transaction retrieves a set of assets from the world state database. Successive rounds increase the page size of assets retrieved from the world state database.","title":"Smart Contract Benchmarks"},{"location":"content/fabric/approach/#notes","text":"The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform. The data contained in the reports was measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources at the end of this report. The performance data cannot be compared across versions of Hyperledger Fabric, as testing hardware and environments may have changed significantly. The testing contents and processing methodologies may have also changed between performance reports, and so cannot be compared.","title":"Notes"},{"location":"content/fabric/downloads/","text":"The reports contained in this site are available for download in pdf format from the table below Fabric Version Chaincode SDK Client Link 1.4.0 JavaScript NodeJS pdf report","title":"Download"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/configuration/","text":"This report was generated using the following Hyperledger Fabric component levels: Fabric images: 1.4.0 Fabric chaincode:1.4.0 Fabric SDK Node: 1.4.0 Machine Configuration Hyperledger Caliper at commit level 4156c4da7105fd1c2b848573a9943bfc9900becb was used. The report was generated on an IBM Cloud Softlayer machine with the following configuration: OS: Ubuntu 16.04-64 RAM: 2x16GB Micron 16GB DDR4 2Rx8 Processor: 3.8GHz Intel Xeon-KabyLake (E3-1270-V6-Quadcore) Motherboard: Lenovo Systemx3250-M6 Firmaware: M3E124G 2.10 10-12-2017 Network Card: Silicom PE310G4i40-T HDD: 960GB SanDisk CloudSpeed 1000 SSD Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 8 On-line CPU(s) list: 0-7 Thread(s) per core: 2 Core(s) per socket: 4 Socket(s): 1 Notes The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform. Measuring transaction throughput demonstrates potential transaction rates, and the impact of the relative cost of different Hyperledger Fabric Stub API calls. The data contained in the reports was measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources at the end of this report. The performance data cannot be compared across versions of Hyperledger Fabric, as testing hardware and environments may have changed significantly. The testing contents and processing methodologies may have also changed between performance reports, and so cannot be compared.","title":"Configuration"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/configuration/#machine-configuration","text":"Hyperledger Caliper at commit level 4156c4da7105fd1c2b848573a9943bfc9900becb was used. The report was generated on an IBM Cloud Softlayer machine with the following configuration: OS: Ubuntu 16.04-64 RAM: 2x16GB Micron 16GB DDR4 2Rx8 Processor: 3.8GHz Intel Xeon-KabyLake (E3-1270-V6-Quadcore) Motherboard: Lenovo Systemx3250-M6 Firmaware: M3E124G 2.10 10-12-2017 Network Card: Silicom PE310G4i40-T HDD: 960GB SanDisk CloudSpeed 1000 SSD Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 8 On-line CPU(s) list: 0-7 Thread(s) per core: 2 Core(s) per socket: 4 Socket(s): 1","title":"Machine Configuration"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/configuration/#notes","text":"The performance information is obtained by measuring the transaction throughput for different types of smart contract transactions. The term \u201ctransaction\u201d is used in a generic sense, and refers to any interaction with a smart contract, regardless of the complexity of the subsequent interaction(s) with the blockchain platform. Measuring transaction throughput demonstrates potential transaction rates, and the impact of the relative cost of different Hyperledger Fabric Stub API calls. The data contained in the reports was measured in a controlled environment, results obtained in other environments might vary. For more details on the environments used, see the resources at the end of this report. The performance data cannot be compared across versions of Hyperledger Fabric, as testing hardware and environments may have changed significantly. The testing contents and processing methodologies may have also changed between performance reports, and so cannot be compared.","title":"Notes"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/batch-get-asset/","text":"The batch asset retrieval benchmark consists of evaluating getAssetsFromBatch gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks that uses a 2-of-any endorsement policy. This will result in the method being run on a single Hyperledger Fabric Peer and will not result in any interaction with the Orderer. The investigated scenarios are targeted at reading from the world state database, resulting in the transaction pathway depicted in Figure 1. Figure 1: Evaluate Transaction Pathway Each transaction retrieves a set of assets, formed by a randomised selection of available UUIDs, from the world state database. Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the batch size of the assets retrieved from the world state database with a fixed asset size of 8Kb. Resource utilization is investigated for a fixed transaction rate of 30TPS and a batch size of 20 assets, each of size 8Kb. Benchmark Results LevelDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.20 0.06 408.7 10 0.48 0.29 75.5 20 1.03 0.56 39.0 30 1.34 0.80 27.9 40 1.68 1.05 21.2 50 2.14 1.29 17.8 CouchDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.15 0.03 388.9 10 0.46 0.18 68.5 20 0.64 0.32 35.6 30 0.84 0.46 24.2 40 1.10 0.60 18.5 50 1.32 0.74 14.9 Resource Utilization- Batch Size 20 @30TPS Benchmark Observations Use of a LevelDB world state enables higher throughput compared to CouchDB, though this occurs with higher latencies for each transaction. In comparing a LevelDB world state database with a CouchDB equivalent during batch retrieve, there are similarities with the Get Asset Benchmark : implementing a CouchDB incurs a greater CPU and network I/O cost without alleviating CPU utilization of the peer.","title":"Batch Get Asset"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/batch-get-asset/#benchmark-results","text":"LevelDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.20 0.06 408.7 10 0.48 0.29 75.5 20 1.03 0.56 39.0 30 1.34 0.80 27.9 40 1.68 1.05 21.2 50 2.14 1.29 17.8 CouchDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.15 0.03 388.9 10 0.46 0.18 68.5 20 0.64 0.32 35.6 30 0.84 0.46 24.2 40 1.10 0.60 18.5 50 1.32 0.74 14.9 Resource Utilization- Batch Size 20 @30TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/batch-get-asset/#benchmark-observations","text":"Use of a LevelDB world state enables higher throughput compared to CouchDB, though this occurs with higher latencies for each transaction. In comparing a LevelDB world state database with a CouchDB equivalent during batch retrieve, there are similarities with the Get Asset Benchmark : implementing a CouchDB incurs a greater CPU and network I/O cost without alleviating CPU utilization of the peer.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/empty-contract/","text":"The Empty Contract Benchmark consists of evaluating emptyContract gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks. This will result on the transaction being run on a single Hyperledger Fabric Peer and will not result in any interaction with the Orderer, resulting in the transaction pathway depicted in Figure 1. Figure 1: Evaluate Transaction Pathway This is repeated for networks that use the following endorsement policies: 1-of-any 2-of-any Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog of 15 transactions for each of the test clients. Resource utilization is investigated for fixed TPS rate of 750TPS. Benchmark Results LevelDB- evaluate transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) evaluate 1-of-any 0.18 0.04 792.3 evaluate 2-of-any 0.18 0.04 796.4 CouchDB- evaluate transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) evaluate 1-of-any 0.16 0.04 789.9 evaluate 2-of-any 0.17 0.04 797.5 LevelDB Resource Utilization\u2013 Evaluate By Policy @750TPS CouchDB Resource Utilization\u2013 Evaluate By Policy @750TPS Resource Utilization\u2013 Evaluate 1ofAny Policy @750TPS Resource Utilization\u2013 Evaluate 2ofAny Policy @750TPS Benchmark Observations With a fixed world state database, the endorsement policy has no impact on the consumed resources when evaluating gateway transactions. In comparing a LevelDB world state database with a CouchDB equivalent, there is no appreciable difference in the achievable transaction throughput or transaction latency, nor the CPU or network I/O consumed by either implementation when varying the endorsement policy. There is a slight cost in additional memory requirements for the use of a CouchDB world state store.","title":"Empty Contract"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/empty-contract/#benchmark-results","text":"LevelDB- evaluate transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) evaluate 1-of-any 0.18 0.04 792.3 evaluate 2-of-any 0.18 0.04 796.4 CouchDB- evaluate transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) evaluate 1-of-any 0.16 0.04 789.9 evaluate 2-of-any 0.17 0.04 797.5 LevelDB Resource Utilization\u2013 Evaluate By Policy @750TPS CouchDB Resource Utilization\u2013 Evaluate By Policy @750TPS Resource Utilization\u2013 Evaluate 1ofAny Policy @750TPS Resource Utilization\u2013 Evaluate 2ofAny Policy @750TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/empty-contract/#benchmark-observations","text":"With a fixed world state database, the endorsement policy has no impact on the consumed resources when evaluating gateway transactions. In comparing a LevelDB world state database with a CouchDB equivalent, there is no appreciable difference in the achievable transaction throughput or transaction latency, nor the CPU or network I/O consumed by either implementation when varying the endorsement policy. There is a slight cost in additional memory requirements for the use of a CouchDB world state store.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/get-asset/","text":"The asset retrieval benchmark consists of evaluating getAsset gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks that uses a 2-of-any endorsement policy. This will result in the method being run on a single Hyperledger Fabric Peer and will not result in any interaction with the Orderer. The investigated scenarios are targeted at reading from the world state database, resulting in the transaction pathway depicted in Figure 1. Figure 1: Evaluate Transaction Pathway Each transaction retrieves a single asset with a randomised UUID from the world state database. Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the size of the asset retrieved from the world state database. Resource utilization is investigated for a fixed transaction rate of 350TPS, retrieving assets of size 8Kb. Benchmark Results LevelDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.34 0.05 636.0 1k 0.21 0.06 611.1 2k 0.23 0.06 579.8 4k 0.20 0.07 516.8 8k 0.19 0.08 423.1 16k 0.24 0.11 293.6 32k 0.35 0.18 186.5 64k 0.73 0.35 96.0 CouchDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 1.10 0.06 567.4 1K 1.06 0.07 558.9 2K 0.24 0.07 531.4 4K 0.25 0.08 478.0 8K 0.26 0.09 395.4 16K 0.29 0.12 306.1 32K 0.36 0.17 208.3 64K 0.75 0.35 107.0 Resource Utilization- 8k Assets @350TPS Benchmark Observations The CouchDB world state database is observed to achieve comparable throughput and lower latencies than a LevelDB equivalent, with higher achievable TPS for assets that are larger than 10Kb. In comparing a LevelDB world state database with a CouchDB equivalent during asset retrieval, both consume similar memory resources, though the CouchDB world state database results in greater network I/O and a CPU overhead for the CouchDB instance that is not offset at the peer.","title":"Get Asset"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/get-asset/#benchmark-results","text":"LevelDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.34 0.05 636.0 1k 0.21 0.06 611.1 2k 0.23 0.06 579.8 4k 0.20 0.07 516.8 8k 0.19 0.08 423.1 16k 0.24 0.11 293.6 32k 0.35 0.18 186.5 64k 0.73 0.35 96.0 CouchDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 1.10 0.06 567.4 1K 1.06 0.07 558.9 2K 0.24 0.07 531.4 4K 0.25 0.08 478.0 8K 0.26 0.09 395.4 16K 0.29 0.12 306.1 32K 0.36 0.17 208.3 64K 0.75 0.35 107.0 Resource Utilization- 8k Assets @350TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/get-asset/#benchmark-observations","text":"The CouchDB world state database is observed to achieve comparable throughput and lower latencies than a LevelDB equivalent, with higher achievable TPS for assets that are larger than 10Kb. In comparing a LevelDB world state database with a CouchDB equivalent during asset retrieval, both consume similar memory resources, though the CouchDB world state database results in greater network I/O and a CPU overhead for the CouchDB instance that is not offset at the peer.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-range-query/","text":"The paginated range query benchmark consists of evaluating paginatedRangeQuery gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks that use a 2-of-any endorsement policy. This will result in the method being run on a single Hyperledger Fabric Peer and will not result in any interaction with the Orderer. The investigated scenarios are targeted at reading from the world state database, resulting in the transaction pathway depicted in Figure 1. Figure 1: Evaluate Transaction Pathway Each transaction retrieves a fixed number of mixed byte size assets in the range [100, 1000, 2000, 4000, 8000, 16000, 32000, 64000] from the world state database. Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the page size of assets retrieved from the world state database. Resource utilization is investigated for a fixed transaction rate of 30TPS and a batch size of 20 assets. Benchmark Results LevelDB Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 0.23 0.16 81.1 20 0.37 0.26 34.0 50 0.86 0.64 11.2 100 1.59 1.23 6.8 200 2.86 2.40 3.6 500 9.02 7.07 0.9 CouchDB Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 0.94 0.42 82.1 20 1.60 0.75 45.9 50 4.09 1.84 19.4 100 8.03 3.57 9.7 200 16.55 5.32 5.0 500 15.96 4.80 1.6 Resource Utilization- Batch Size 20 @30TPS Benchmark Observations Use of a CouchDB world state database enables greater throughput but higher latencies than the LevelDB equivalent. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during a range query, the CouchDB world state incurs a cost in memory, network I/O and CPU utilization. In particular, use of a CouchDB world state for a range query is observed to result in significant increases in CPU and memory utilization in the peer, with an associated increase in network I/O as a result of communication with the CouchDB instance. When comparing the range query page sizes against a matching batch size in the Get Asset Batch Benchmark , it is observed to be more efficient to use a batch retrieval mechanism with known UUIDs.","title":"Paginated Rage Query"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-range-query/#benchmark-results","text":"LevelDB Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 0.23 0.16 81.1 20 0.37 0.26 34.0 50 0.86 0.64 11.2 100 1.59 1.23 6.8 200 2.86 2.40 3.6 500 9.02 7.07 0.9 CouchDB Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 0.94 0.42 82.1 20 1.60 0.75 45.9 50 4.09 1.84 19.4 100 8.03 3.57 9.7 200 16.55 5.32 5.0 500 15.96 4.80 1.6 Resource Utilization- Batch Size 20 @30TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-range-query/#benchmark-observations","text":"Use of a CouchDB world state database enables greater throughput but higher latencies than the LevelDB equivalent. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during a range query, the CouchDB world state incurs a cost in memory, network I/O and CPU utilization. In particular, use of a CouchDB world state for a range query is observed to result in significant increases in CPU and memory utilization in the peer, with an associated increase in network I/O as a result of communication with the CouchDB instance. When comparing the range query page sizes against a matching batch size in the Get Asset Batch Benchmark , it is observed to be more efficient to use a batch retrieval mechanism with known UUIDs.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-rich-query/","text":"The pageinated rich query enchmark consists of evaluating paginatedRichQuery gateway transactions for the fixed-asset smart contract deployed within a CouchDB network that uses a 2-of-any endorsement policy. This will result in the method being run on a single Hyperledger Fabric Peer and will not result in any interaction with the Orderer. The investigated scenarios are targeted at reading from the world state database, resulting in the transaction pathway depicted in Figure 1. Figure 1: Evaluate Transaction Pathway Each transaction retrieves a fixed number of mixed byte size assets in the range [100, 1000, 2000, 4000, 8000, 16000, 32000, 64000] from the world state database based on the following Mango query that matches an index created in CouchDB: { 'selector': { 'docType': 'fixed-asset', 'creator': 'clientId\u2019, 'bytesize': 'bytesize' } } Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the page size of assets retrieved from the world state database. Benchmark Results Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 21.68 0.29 80.9 20 14.58 0.77 30.8 50 15.13 2.08 12.1 100 16.31 3.75 7.1 200 23.35 6.41 3.9 500 23.48 4.49 1.1 Benchmark Observations Increasing the page size of a rich query has significant impact on the achievable throughput and latency. This corresponds with significantly increased network I/O across the target peer, smart contract and the CouchDB world state database. Inspection of the resource utilization statistics for the individual benchmark runs show that the peer must deal with a significant network I/O load. This is a result of the peer obtaining and relaying the information from CouchDB to the smart contract transaction, and then passing back the resulting data from the smart contract transaction to the calling client application.","title":"Paginated Rich Query"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-rich-query/#benchmark-results","text":"Page Size Max Latency (s) Avg Latency (s) Throughput (TPS) 10 21.68 0.29 80.9 20 14.58 0.77 30.8 50 15.13 2.08 12.1 100 16.31 3.75 7.1 200 23.35 6.41 3.9 500 23.48 4.49 1.1","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/evaluate/paginated-rich-query/#benchmark-observations","text":"Increasing the page size of a rich query has significant impact on the achievable throughput and latency. This corresponds with significantly increased network I/O across the target peer, smart contract and the CouchDB world state database. Inspection of the resource utilization statistics for the individual benchmark runs show that the peer must deal with a significant network I/O load. This is a result of the peer obtaining and relaying the information from CouchDB to the smart contract transaction, and then passing back the resulting data from the smart contract transaction to the calling client application.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/batch-create-asset/","text":"The batch create asset benchmark consists of submitting createAssetsFromBatch gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks that uses a 2-of-any endorsement policy. This will result on the method being run on Hyperledger Fabric Peers as required by the endorsement policy and appended to the ledger by the Orderer. The investigated scenarios are targeted at writing to the world state database, resulting in the transaction pathway as depicted in Figure 1. Figure 1: Submit Transaction Pathway Each transaction inserts a set of assets into the world state database. Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the batch size of the assets inserted into the world state database with a fixed asset size of 8Kb. Resource utilization is investigated for a fixed transaction rate of 15TPS and a batch size of 20. Benchmark Results LevelDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.55 0.11 129.8 10 0.85 0.39 39.1 20 2.04 0.72 19.7 30 1.67 0.91 15.5 40 2.39 1.22 11.1 50 8.83 2.02 7.4 CouchDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.55 0.15 104.9 10 0.93 0.48 31.4 20 1.99 0.80 18.4 30 2.14 1.13 12.7 40 2.82 1.42 9.8 50 3.29 1.77 7.5 Resource Utilization- Batch Size 20 @15TPS Benchmark Observations Use of a LevelDB world state database is seen to enable higher throughput and lower latencies with small batch sizes, though this benefit is lost with large batch sizes. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during batch asset creation, there are similarities with the Create Asset Benchmark : implementing a CouchDB world state is CPU intensive, but is observed to be beneficial in terms of disc I/O.","title":"Batch Create Asset"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/batch-create-asset/#benchmark-results","text":"LevelDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.55 0.11 129.8 10 0.85 0.39 39.1 20 2.04 0.72 19.7 30 1.67 0.91 15.5 40 2.39 1.22 11.1 50 8.83 2.02 7.4 CouchDB Batch Size Max Latency (s) Avg Latency (s) Throughput (TPS) 1 0.55 0.15 104.9 10 0.93 0.48 31.4 20 1.99 0.80 18.4 30 2.14 1.13 12.7 40 2.82 1.42 9.8 50 3.29 1.77 7.5 Resource Utilization- Batch Size 20 @15TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/batch-create-asset/#benchmark-observations","text":"Use of a LevelDB world state database is seen to enable higher throughput and lower latencies with small batch sizes, though this benefit is lost with large batch sizes. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during batch asset creation, there are similarities with the Create Asset Benchmark : implementing a CouchDB world state is CPU intensive, but is observed to be beneficial in terms of disc I/O.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/create-asset/","text":"The create asset benchmark consists of submitting createAsset gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks that uses a 2-of-any endorsement policy. This will result on the method being run on Hyperledger Fabric Peers as required by the endorsement policy and appended to the ledger by the Orderer. The investigated scenarios are targeted at writing to the world state database, resulting in the transaction pathway as depicted in Figure 1. Figure 1: Submit Transaction Pathway Each transaction inserts a single asset into the world state database. Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog for each of the test clients. Successive rounds increase the size of the asset inserted into the world state database. Resource utilization is investigated for a fixed transaction rate of 125TPS and an asset size of 8Kb. Benchmark Results LevelDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.48 0.11 372.5 2k 0.55 0.13 329.2 4k 0.60 0.14 294.7 8k 0.71 0.17 242.0 16k 0.76 0.23 177.6 32k 0.95 0.35 114.3 64k 1.45 0.62 61.2 CouchDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.71 0.22 194.0 2K 0.57 0.24 179.2 4K 0.54 0.26 164.1 8K 0.74 0.29 147.7 16K 0.88 0.36 119.9 32K 0.99 0.48 88.3 64K 1.58 0.77 51.7 Resource Utilization- 8k Assets @125TPS Benchmark Observations LevelDB facilitates asset addition at higher TPS and lower latencies than CouchDB. The throughput advantage of LevelDB is lessened with large asset sizes, but the latency advantage is retained. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during asset creation, a CouchDB world state is CPU intensive, but is beneficial in terms of disc I/O.","title":"Create Asset"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/create-asset/#benchmark-results","text":"LevelDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.48 0.11 372.5 2k 0.55 0.13 329.2 4k 0.60 0.14 294.7 8k 0.71 0.17 242.0 16k 0.76 0.23 177.6 32k 0.95 0.35 114.3 64k 1.45 0.62 61.2 CouchDB Asset Size (bytes) Max Latency (s) Avg Latency (s) Throughput (TPS) 100 0.71 0.22 194.0 2K 0.57 0.24 179.2 4K 0.54 0.26 164.1 8K 0.74 0.29 147.7 16K 0.88 0.36 119.9 32K 0.99 0.48 88.3 64K 1.58 0.77 51.7 Resource Utilization- 8k Assets @125TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/create-asset/#benchmark-observations","text":"LevelDB facilitates asset addition at higher TPS and lower latencies than CouchDB. The throughput advantage of LevelDB is lessened with large asset sizes, but the latency advantage is retained. In comparing the resource utilization of a LevelDB world state database with a CouchDB equivalent during asset creation, a CouchDB world state is CPU intensive, but is beneficial in terms of disc I/O.","title":"Benchmark Observations"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/empty-contract/","text":"The Empty Contract Benchmark consists of submitting emptyContract gateway transactions for the fixed-asset smart contract deployed within LevelDB and CouchDB networks. When submitting emptyContract gateway transactions, the interaction is recorded on the ledger. This results in the transaction pathway as depicted in Figure 1. Figure 1: Submit Empty Contract Transaction Pathway This is repeated for networks that use the following endorsement policies: 1-of-any 2-of-any Achievable throughput and associated latencies are investigated through maintaining a constant transaction backlog of 15 transactions for each of the test clients. Resource utilization is investigated for fixed TPS rate of 350TPS. Benchmark Results LevelDB- submit transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) submit 1-of-any 0.41 0.09 485.4 submit 2-of-any 0.33 0.10 420.0 CouchDB- submit transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) submit 1-of-any 0.52 0.11 380.5 submit 2-of-any 0.32 0.13 3387 LevelDB Resource Utilization\u2013 Submit By Policy @750TPS CouchDB Resource Utilization\u2013 Submit By Policy @750TPS Resource Utilization\u2013 Submit 1ofAny Policy @750TPS Resource Utilization\u2013 Submit 2ofAny Policy @750TPS Benchmark Observations LevelDB is observed to be beneficial for achievable throughput and reduced latencies in comparison to CouchDB during submission of an emptyContract gateway transaction for both investigated endorsement policies. With a fixed world state database, the endorsement policy is observed to impact the consumed resources when submitting a transaction. Increasing the number of required endorsements is observed to increase the CPU and network I/O, through inclusion of additional peers and smart contract containers required to participate in each transaction. In comparing a LevelDB world state database with a CouchDB equivalent, only the network I/O is observed to be equivalent when varying the endorsement policy. There is an observed penalty in additional memory, CPU and disc I/O requirements for the use of a CouchDB world state for the network as a whole, though the memory requirements of the peers are reduced.","title":"Empty Contract"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/empty-contract/#benchmark-results","text":"LevelDB- submit transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) submit 1-of-any 0.41 0.09 485.4 submit 2-of-any 0.33 0.10 420.0 CouchDB- submit transactions with varying endorsement policy Type Policy Max Latency (s) Avg Latency (s) Throughput (TPS) submit 1-of-any 0.52 0.11 380.5 submit 2-of-any 0.32 0.13 3387 LevelDB Resource Utilization\u2013 Submit By Policy @750TPS CouchDB Resource Utilization\u2013 Submit By Policy @750TPS Resource Utilization\u2013 Submit 1ofAny Policy @750TPS Resource Utilization\u2013 Submit 2ofAny Policy @750TPS","title":"Benchmark Results"},{"location":"content/fabric/1.4.0/nodeJS/nodeSDK/submit/empty-contract/#benchmark-observations","text":"LevelDB is observed to be beneficial for achievable throughput and reduced latencies in comparison to CouchDB during submission of an emptyContract gateway transaction for both investigated endorsement policies. With a fixed world state database, the endorsement policy is observed to impact the consumed resources when submitting a transaction. Increasing the number of required endorsements is observed to increase the CPU and network I/O, through inclusion of additional peers and smart contract containers required to participate in each transaction. In comparing a LevelDB world state database with a CouchDB equivalent, only the network I/O is observed to be equivalent when varying the endorsement policy. There is an observed penalty in additional memory, CPU and disc I/O requirements for the use of a CouchDB world state for the network as a whole, though the memory requirements of the peers are reduced.","title":"Benchmark Observations"}]}